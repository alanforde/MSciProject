{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents:\n",
    "* [Set Up](#setup)\n",
    "* [Support](#support)\n",
    "* [Implicit](#implicit)\n",
    "* [SciPy](#scipy)\n",
    "* [Spotlight Sequence Recommender](#spot_seq)\n",
    "* [Spotlight ALS](#spot)\n",
    "* [Features](#features)\n",
    "* [Evaluation](#eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "======================= SET UP ======================= <a class=\"anchor\" id=\"setup\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ORDER_SAMPLE_SIZE = 1000 #Number of orders we want to use a sample\n",
    "MIN_PURCHASES = 30 #How many purchases needed per order to be included in sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "purchases = pd.read_csv(\"Instacart_data/order_products__prior.csv\")\n",
    "purchases.drop(['add_to_cart_order', 'reordered'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products = pd.read_csv(\"Instacart_data/products.csv\")\n",
    "products.drop(['aisle_id', 'department_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orders = pd.read_csv(\"Instacart_data/orders.csv\")\n",
    "orders.drop(['eval_set', 'order_number', 'order_dow', 'order_hour_of_day', 'days_since_prior_order'], axis=1, inplace=True)\n",
    "orders.set_index('order_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "purchases = purchases.join(orders, on='order_id')\n",
    "purchases['purchased'] = np.ones(len(purchases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "purchases.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listed_df = pd.DataFrame(purchases.groupby('order_id')['product_id'].apply(list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listed_df['test_prod'] = listed_df.product_id.apply(lambda x: x[-1])\n",
    "listed_df['product_id'] = listed_df.product_id.apply(lambda x: x[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lastInBasket = listed_df.drop('product_id', axis=1).rename(columns = {'test_prod': 'product_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "purchases2 = (listed_df.product_id.apply(pd.Series).stack().reset_index(level=1, drop=True).to_frame('product_id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "purchases = purchases2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "purchases.reset_index(inplace=True)\n",
    "purchaseCount = purchases.groupby('order_id').count()\n",
    "largeOrders = purchaseCount[purchaseCount['product_id'] >= MIN_PURCHASES]\n",
    "largeOrders = largeOrders.sample(ORDER_SAMPLE_SIZE, random_state=42)\n",
    "purchases = purchases.loc[purchases.order_id.isin(largeOrders.index.values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "purchases['purchased'] = np.ones(len(purchases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "equiv_id_orders=  {}\n",
    "order = 0\n",
    "for order_id in np.unique(purchases.order_id.values):\n",
    "    equiv_id_orders[order_id] = order\n",
    "    order += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "equiv_id_prods =  {}\n",
    "prod = 1\n",
    "for product_id in np.unique(purchases.product_id.values):\n",
    "    equiv_id_prods[product_id] = prod\n",
    "    prod += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "implicit_equiv_id_prods =  {}\n",
    "prod = 0\n",
    "for product_id in np.unique(purchasesWithFinal.product_id.values):\n",
    "    implicit_equiv_id_prods[product_id] = prod\n",
    "    prod += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "implicit_equiv_prod_DF = pd.DataFrame.from_dict(implicit_equiv_id_prods, orient='index')\n",
    "implicit_equiv_prod_DF.rename(columns = {0: 'equiv_product_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## If we want to ensure the next product purchased by every order is infact in the model\n",
    "lastProducts = lastInBasket.reset_index()\n",
    "lastProducts = lastProducts[lastProducts.order_id.isin(purchases.order_id.values)]\n",
    "lastProducts['order_id'] = lastProducts.order_id.apply(lambda x: 1)\n",
    "lastProducts['purchased'] = np.ones(len(lastProducts))\n",
    "lastProducts.drop_duplicates(inplace=True)\n",
    "purchasesWithFinal = pd.concat([lastProducts, purchases])\n",
    "purchasesWithFinal.reset_index(inplace=True)\n",
    "purchasesWithFinal.drop(['index'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "======================= SUPPORT ======================= <a class=\"anchor\" id=\"support\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "productCount = purchases.groupby('product_id').count().sort_values('order_id', ascending=0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "productCount.reset_index(inplace=True)\n",
    "productCount['pop_rank'] = productCount['index'].apply(lambda x: x+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "supportDF = productCount['product_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getSupportRecs():\n",
    "    recs_dict = {}\n",
    "    for order in np.unique(purchases.order_id.values):\n",
    "        recs_dict[order] = supportDF.values\n",
    "    return recs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "support_recs = getSupportRecs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "======================= IMPLICIT ======================= <a class=\"anchor\" id=\"implicit\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import implicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "implicit_userPurchases = purchasesWithFinal.pivot(index = 'product_id', columns ='order_id', values = 'purchased').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "implicit_purchaseMatrix = implicit_userPurchases.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "implicit_purchaseMatrix = scipy.sparse.csr_matrix(implicit_userPurchases.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "implicit_als_model = implicit.als.AlternatingLeastSquares(factors=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15.0/15 [00:08<00:00,  1.65it/s]\n"
     ]
    }
   ],
   "source": [
    "implicit_als_model.fit(implicit_purchaseMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_items = implicit_purchaseMatrix.T.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top100real = support_recs[546][:100]    ##arbitrary ID, support_recs are the same for everyone\n",
    "top100equiv = []\n",
    "for product in top100real:\n",
    "    top100equiv += [implicit_equiv_prod_DF.loc[product].values[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_implicit_recs():\n",
    "    recs_dict = {}\n",
    "    for order in np.unique(purchases.order_id.values):\n",
    "        trueNext = lastInBasket.loc[order].values[0]\n",
    "        equivTruthId = implicit_equiv_prod_DF.loc[trueNext].values[0]\n",
    "        items2rank = top100equiv[:]\n",
    "        items2rank += [equivTruthId]\n",
    "        recommendations = implicit_als_model.rank_items(equiv_id_orders[order], user_items, items2rank)\n",
    "        recs_list = []\n",
    "        for rec in recommendations:\n",
    "            recs_list += [implicit_equiv_prod_DF.loc[implicit_equiv_prod_DF.equiv_product_id == rec[0]].index.values[0]]\n",
    "        recs_dict[order] = recs_list\n",
    "    return recs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recs_dict = {}\n",
    "for order in [546]:#np.unique(purchases.order_id.values):\n",
    "    trueNext = lastInBasket.loc[order].values[0]\n",
    "    equivTruthId = implicit_equiv_prod_DF.loc[trueNext].values[0]\n",
    "    items2rank = top100equiv[:]\n",
    "    items2rank += [equivTruthId]\n",
    "    recommendations = implicit_als_model.rank_items(equiv_id_orders[order], user_items, items2rank)\n",
    "    recs_list = []\n",
    "    for rec in recommendations:\n",
    "        recs_list += [implicit_equiv_prod_DF.loc[implicit_equiv_prod_DF.equiv_product_id == rec[0]].index.values[0]]\n",
    "    recs_dict[order] = recs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "implicit_recs = get_implicit_recs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "======================= SCIPY ======================= <a class=\"anchor\" id=\"scipy\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scipy_userPurchases = purchases.pivot(index = 'order_id', columns ='product_id', values = 'purchased').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scipy_purchaseMatrix = scipy_userPurchases.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import svds\n",
    "U, sigma, Vt = svds(scipy_purchaseMatrix, k = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sigma = np.diag(sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_user_predicted_ratings = np.dot(np.dot(U, sigma), Vt)\n",
    "preds_df = pd.DataFrame(all_user_predicted_ratings, index = scipy_userPurchases.index.values, columns = scipy_userPurchases.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_scipy_recs():\n",
    "    recs_dict = {}\n",
    "    for order in np.unique(purchases.order_id.values):\n",
    "        sorted_order_predictions = preds_df.loc[order].sort_values(ascending=False)\n",
    "        order_data = purchases[purchases.order_id == (order)]\n",
    "        ##filtered_preds = (order_data.merge(products, how = 'left', left_on = 'product_id', right_on = 'product_id').sort_values(['purchased'], ascending=False))\n",
    "        recommendations = (products[~products['product_id'].isin(order_data['product_id'])].\n",
    "         merge(pd.DataFrame(sorted_order_predictions).reset_index(), how = 'left',\n",
    "           left_on = 'product_id',\n",
    "           right_on = 'product_id').rename(columns = {order: 'Predictions'}).\n",
    "         sort_values('Predictions', ascending = False).\n",
    "                   iloc[:10044, :-1]\n",
    "                  )\n",
    "        recs_dict[order] = recommendations.product_id.values\n",
    "    return recs_dict\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scipy_recs = get_scipy_recs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "======================= SPOTLIGHT SEQUENCE RECOMMENDER ======================= <a class=\"anchor\" id=\"spot_seq\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from spotlight.cross_validation import random_train_test_split\n",
    "from spotlight.factorization.implicit import ImplicitFactorizationModel\n",
    "from spotlight.sequence.implicit import ImplicitSequenceModel\n",
    "from spotlight import interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "withTimes = pd.read_csv(\"Instacart_data/order_products__prior.csv\")\n",
    "withTimes.drop(['reordered'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "purchasesWithTimes = pd.merge(purchases, withTimes,  how='left', left_on=['order_id','product_id'], right_on = ['order_id','product_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "purchasesWithTimes['equiv_prod_id'] = purchasesWithTimes.product_id.apply(lambda x: equiv_id_prods[x])\n",
    "purchasesWithTimes['equiv_order_id'] = purchasesWithTimes.order_id.apply(lambda x: equiv_id_orders[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orders = purchasesWithTimes.equiv_order_id.values.astype(np.int32)\n",
    "prods = purchasesWithTimes.equiv_prod_id.values.astype(np.int32)\n",
    "timestamps = purchasesWithTimes.add_to_cart_order.values.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = interactions.Interactions(orders, prods, timestamps=timestamps)\n",
    "dataset = dataset.to_sequence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spotlight_seq_model = ImplicitSequenceModel(n_iter=10,\n",
    "                              representation='cnn',\n",
    "                              loss='bpr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spotlight_seq_model.fit(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_spotlight_seq_recs():\n",
    "    recs_dict = {}\n",
    "    for order in np.unique(purchases.order_id.values):\n",
    "        recs_list = []\n",
    "        productScores = spotlight_seq_model.predict(purchasesWithTimes.loc[purchasesWithTimes.order_id == order, 'equiv_prod_id'].values)\n",
    "        recsDF = pd.DataFrame({'product':np.unique(purchasesWithTimes.equiv_prod_id.values), 'score':productScores[1:]})\n",
    "        recsDF.sort_values('score', ascending=0, inplace=True)\n",
    "        recommendations = recsDF['product'].values[:1000]\n",
    "        for rec in recommendations:\n",
    "            recs_list += [implicit_equiv_prod_DF.loc[implicit_equiv_prod_DF.equiv_product_id == rec-1].index.values[0]]\n",
    "        recs_dict[order] = recs_list\n",
    "    return recs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spotlight_seq_recs = get_spotlight_seq_recs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "======================= SPOTLIGHT ======================= <a class=\"anchor\" id=\"spot\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from spotlight.cross_validation import random_train_test_split\n",
    "from spotlight.factorization.implicit import ImplicitFactorizationModel\n",
    "from spotlight import interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spotlight_data = interactions.Interactions(orders, prods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spotlight_ifm_model = ImplicitFactorizationModel(n_iter=10,\n",
    "                                   loss='bpr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spotlight_ifm_model.fit(spotlight_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_spotlight_recs():\n",
    "    recs_dict = {}\n",
    "    for order in np.unique(purchases.order_id.values):\n",
    "        recommendations = spotlight_ifm_model.predict(purchasesWithTimes.loc[purchasesWithTimes.equiv_order_id == equiv_id_orders[order], 'equiv_prod_id'].values)\n",
    "        recs_dict[order] = recommendations\n",
    "    return recs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Maximum user id greater than number of users in model.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-d36e5f1f3872>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mspotlight_recs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_spotlight_recs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-74-d43cc807775e>\u001b[0m in \u001b[0;36mget_spotlight_recs\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mrecs_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0morder\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpurchases\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morder_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mrecommendations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspotlight_ifm_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpurchasesWithTimes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpurchasesWithTimes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequiv_order_id\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mequiv_id_orders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'equiv_prod_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mrecs_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecommendations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrecs_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/alanforde1/anaconda2/lib/python2.7/site-packages/spotlight/factorization/implicit.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, user_ids, item_ids)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \"\"\"\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_items_none\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/alanforde1/anaconda2/lib/python2.7/site-packages/spotlight/factorization/implicit.pyc\u001b[0m in \u001b[0;36m_check_input\u001b[0;34m(self, user_ids, item_ids, allow_items_none)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muser_id_max\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_users\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             raise ValueError('Maximum user id greater '\n\u001b[0m\u001b[1;32m    170\u001b[0m                              'than number of users in model.')\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Maximum user id greater than number of users in model."
     ]
    }
   ],
   "source": [
    "spotlight_recs = get_spotlight_recs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "======================= FEATURES =======================  <a class=\"anchor\" id=\"features\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import gensim\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format('./GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-5baf911187ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mprod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mproductNamesDF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproductNamesDF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'product_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mprod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m1000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/alanforde1/anaconda2/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   2353\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2354\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2355\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2357\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/src/inference.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-5baf911187ef>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mprod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mproductNamesDF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproductNamesDF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'product_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mprod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m1000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Build one-hot encoding dataframe\n",
    "productsNames = pd.read_csv(\"Instacart_data/products.csv\")\n",
    "productNames = products[['product_name']].values\n",
    "splitProducts = []\n",
    "for product in productNames:\n",
    "    productName = product[0].lower()\n",
    "    productList = productName.split()\n",
    "    splitProducts += [productList]\n",
    "productNamesDF = products[['product_name']]\n",
    "vocab = np.concatenate(splitProducts)\n",
    "vocab = np.unique(vocab)\n",
    "count = 0 \n",
    "for prod in vocab:\n",
    "    productNamesDF[prod] = productNamesDF['product_name'].apply(lambda x: 1 if prod in x else 0)\n",
    "    count += 1\n",
    "    if (count%1000 == 0): print (count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Build product embedding dataframe by averaging embeddings of component words\n",
    "products_df = pd.read_csv(\"Instacart_data/products.csv\")\n",
    "productNames = products_df[['product_name']].values\n",
    "products_df['split_product_name'] = products_df.product_name.apply(lambda x: x.split())\n",
    "stacked_products_df  = (products_df.split_product_name.apply(pd.Series).stack().reset_index(level=1, drop=True).to_frame('product_words'))\n",
    "stacked_products_df['product_words'] = stacked_products_df.product_words.apply(lambda x: x.translate(None, string.punctuation).lower())\n",
    "products_df.reset_index(inplace=True)\n",
    "products_df = products_df.join(stacked_products_df, on='index')\n",
    "column_headers= []\n",
    "for i in range(1,301):\n",
    "    header = \"prod_embed_\" + str(i)\n",
    "    column_headers += [header]\n",
    "products_df[\"word_embedding\"] = pd.DataFrame(products_df.product_words.apply(lambda x: model[x] if x in model.vocab else np.ones(300)))\n",
    "products_df[column_headers] = pd.DataFrame(products_df.word_embedding.values.tolist(), index= products_df.index)\n",
    "product_embeddings_df = products_df.groupby('product_id').mean().drop(['index'], axis=1)\n",
    "product_embeddings_df.drop(['aisle_id', 'department_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prod_column_headers= []\n",
    "for i in range(1,301):\n",
    "    header = \"prod_embed_\" + str(i)\n",
    "    prod_column_headers += [header]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "order_column_headers= []\n",
    "for i in range(1,301):\n",
    "    header = \"basket_embed_\" + str(i)\n",
    "    order_column_headers += [header]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "productHeaderToOrderHeader = {}\n",
    "for header in range(0, len(prod_column_headers)):\n",
    "    productHeaderToOrderHeader[prod_column_headers[header]] = order_column_headers[header]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_RECS=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "purchase_data = listed_df.copy()\n",
    "purchase_data.reset_index(inplace=True)\n",
    "purchase_data.rename(columns = {'product_id': 'basket', 'test_prod':'nextInBasket'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Get additional information about user/basket so that features can be computed\n",
    "def get_order_info_df(recs_dict):\n",
    "    orders = []\n",
    "    for order in recs_dict:\n",
    "        orders += [purchase_data.loc[purchase_data.order_id == order]]\n",
    "    order_info_df = pd.concat(orders, ignore_index=True)\n",
    "    order_info_df['recommendation'] = order_info_df.order_id.apply(lambda x: recs_dict[x][:NUM_RECS])\n",
    "    order_info_df.set_index('order_id', inplace=True)\n",
    "    order_info_df2 = (order_info_df.recommendation.apply(pd.Series).stack().reset_index(level=1, drop=True).to_frame('recommendation'))\n",
    "    order_info_df.drop(['recommendation'], axis=1, inplace = True)\n",
    "    order_info_df = order_info_df.join(order_info_df2)\n",
    "    order_info_df['label'] = order_info_df.nextInBasket == order_info_df.recommendation\n",
    "    return order_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#implicit_order_info = get_order_info_df(implicit_recs)\n",
    "scipy_order_info = get_order_info_df(scipy_recs)\n",
    "#spotseq_order_info = get_order_info_df(spotlight_seq_recs)\n",
    "#support_order_info = get_order_info_df(support_recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def appendUserFeatures(order_info_df):\n",
    "    order_info = order_info_df.copy()\n",
    "    \n",
    "    ## Basic Features; order count, average order day, hour and time between orders\n",
    "    orders = pd.read_csv(\"Instacart_data/orders.csv\")\n",
    "    countById = orders.groupby(['user_id']).count()\n",
    "    meanById = orders.groupby(['user_id']).mean()\n",
    "    userCountDF = countById[['order_id']].copy().rename(index=str, columns={\"order_id\": \"order_count\"})\n",
    "    userMeanDF = meanById[['order_dow', 'order_hour_of_day', 'days_since_prior_order']].copy().rename(index=str, columns={'order_dow' : 'avg_order_day', 'order_hour_of_day': 'avg_order_hour', 'days_since_prior_order' : 'avg_days_between_orders'}).round(0)\n",
    "    userDF = userCountDF.join(userMeanDF)\n",
    "\n",
    "    ## KMeans Clustering\n",
    "    kmeans = KMeans(n_clusters=5, random_state=0)\n",
    "    kmeans.fit(userDF)\n",
    "    labels = kmeans.labels_\n",
    "    userDF = userDF.join(pd.DataFrame(labels, index=userDF.index, columns=['cluster']))\n",
    "    userDF.set_index(userDF.index.astype(np.int32), inplace=True)\n",
    "\n",
    "    ## Average Aisle and Department User shops in\n",
    "    products_aisle_dept = pd.read_csv(\"Instacart_data/products.csv\")\n",
    "    products_aisle_dept = products_aisle_dept[['product_id','aisle_id', 'department_id']].copy()\n",
    "    products_aisle_dept.set_index('product_id', inplace=True)\n",
    "    user_aisle_dept = pd.read_csv(\"Instacart_data/order_products__prior.csv\")\n",
    "    user_aisle_dept = user_aisle_dept.join(orders.set_index('order_id'), on='order_id')\n",
    "    user_aisle_dept = user_aisle_dept[['order_id', 'product_id', 'user_id']].copy()\n",
    "    user_aisle_dept = user_aisle_dept.join(products_aisle_dept, on='product_id')\n",
    "    user_aisle_dept =  user_aisle_dept.groupby(['user_id']).mean()\n",
    "    user_aisle_dept.drop(['order_id', 'product_id'], axis=1, inplace=True)\n",
    "    user_aisle_dept.rename(columns={\"aisle_id\": \"avg_user_aisle\", \"department_id\":\"avg_user_dept\"}, inplace=True)\n",
    "\n",
    "    ## Get user_id from order_id to join features\n",
    "    order_info.reset_index(inplace=True)\n",
    "    order_info = order_info.join(orders[['order_id', 'user_id']].set_index('order_id'), on='order_id')\n",
    "\n",
    "    ## Join features\n",
    "    order_info = order_info.join(userDF, on='user_id')\n",
    "    order_info = order_info.join(user_aisle_dept, on='user_id')\n",
    "    order_info.drop(['user_id'], axis=1, inplace=True)\n",
    "    \n",
    "    return order_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def appendRecommendedProductFeatures(order_info_df):\n",
    "    order_info = order_info_df.copy()\n",
    "    purchase_data = pd.read_csv(\"Instacart_data/order_products__prior.csv\")\n",
    "    order_data = pd.read_csv(\"Instacart_data/orders.csv\")\n",
    "    product_data = pd.read_csv(\"Instacart_data/products.csv\")\n",
    "    \n",
    "    ## Aisle and Department of Product\n",
    "    product_data.set_index('product_id', inplace=True)\n",
    "    product_data.drop(['product_name'], axis=1, inplace=True)\n",
    "    product_data.rename(columns={'aisle_id': 'R_aisle_id', 'department_id': 'R_department_id'})\n",
    "    order_info.join(product_data, on='recommendation')\n",
    "    \n",
    "    ## Average hour, day, time added to cart and interval at which product is ordered\n",
    "    productsPerOrder = purchase_data.join(order_data.set_index('order_id'), on='order_id')\n",
    "    product_mean_stats = productsPerOrder.groupby('product_id').mean()\n",
    "    product_mean_stats.drop(['order_id', 'reordered', 'user_id', 'order_number'], axis=1, inplace=True)\n",
    "    product_mean_stats.rename(columns = {'add_to_cart_order': 'R_avg_order_in_cart', 'order_dow': 'R_avg_day_of_week', 'order_hour_of_day': 'R_avg_hour_of_day', 'days_since_prior_order': 'R_avg_interval'}, inplace=True)\n",
    "    order_info = order_info.join(product_mean_stats, on='recommendation')\n",
    "    \n",
    "    ## Append word embeddings for each product\n",
    "    order_info = order_info.join(product_embeddings_df, on='recommendation')\n",
    "    \n",
    "\n",
    "    ## Has user ever purchased this product before?\n",
    "    productsPerUser = purchase_data.join(order_data.set_index('order_id'), on='order_id')\n",
    "    productsPerUser = pd.DataFrame(productsPerUser.groupby('user_id')['product_id'].apply(list))\n",
    "    userProductsPerOrder = productsPerUser.join(order_data.set_index('user_id'))\n",
    "    userProductsPerOrder.drop(['eval_set', 'order_number', 'order_dow', 'order_hour_of_day', 'days_since_prior_order'], axis=1, inplace=True)\n",
    "    userProductsPerOrder.rename(columns = {'product_id': 'previous_purchases'}, inplace=True)\n",
    "    userProductsPerOrder.set_index('order_id', inplace=True)\n",
    "    order_info = order_info.join(userProductsPerOrder)\n",
    "    order_info['rec_purchased_before'] = order_info.apply(lambda x: x.recommendation in x.previous_purchases, axis=1)\n",
    "    order_info.drop(['previous_purchases'], inplace=True)\n",
    "    ## one-hot encoding for product\n",
    "\n",
    "    return order_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def appendBasketFeatures(order_info_df):\n",
    "    order_info = order_info_df.copy()\n",
    "    orders_data = pd.read_csv(\"Instacart_data/orders.csv\")\n",
    "    \n",
    "    ## Basket Size\n",
    "    order_info['B_size'] = order_info.basket.apply(lambda x: len(x))\n",
    "    \n",
    "    ## Basket day of week, time of day, and time since last order\n",
    "    orders_data.set_index('order_id', inplace=True)\n",
    "    order_info = order_info.join(orders_data)\n",
    "    order_info.drop(['user_id', 'eval_set', 'order_number'], axis=1, inplace=True)\n",
    "    order_info.rename(columns = {'order_dow': 'B_day_of_week', 'order_hour_of_day': 'B_hour_of_day', 'days_since_prior_order': 'B_time_since_last_order'}, inplace=True)\n",
    "    \n",
    "    ## Basket Embedding -- average of products in basket\n",
    "    order_basket_df = order_info[['order_id','basket']]\n",
    "    order_basket_df.set_index('order_id', inplace=True)\n",
    "    order_basket_df = (order_basket_df.basket.apply(pd.Series).stack().reset_index(level=1, drop=True).to_frame('basketProduct'))\n",
    "    order_basket_df.reset_index(inplace=True)\n",
    "    order_basket_df.drop_duplicates(inplace=True)\n",
    "    embedded_order_basket_df = order_basket_df.join(product_embeddings_df, on='basketProduct')\n",
    "    embedded_order_basket_df.reset_index(inplace=True)\n",
    "    embedded_order_basket_df = embedded_order_basket_df.groupby('order_id').mean()\n",
    "    embedded_order_basket_df.rename(columns = productHeaderToOrderHeader, inplace=True)\n",
    "    order_info = order_info.join(embedded_order_basket_df, on='order_id')\n",
    "    \n",
    "    \n",
    "    return order_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def appendFeatures(order_info_df):\n",
    "    order_info = order_info_df.copy()\n",
    "    order_info = appendUserFeatures(order_info)\n",
    "    order_info = appendRecommendedProductFeatures(order_info)\n",
    "    order_info = appendBasketFeatures(order_info)\n",
    "    return order_info\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "withFeatures = appendFeatures(scipy_order_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "======================= XGBOOST =======================  <a class=\"anchor\" id=\"xgboost\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_labels = withFeatures[['label', 'order_id']]\n",
    "xgb_data = withFeatures.drop(['label', 'basket', 'nextInBasket', 'recommendation'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Need to define our own to ensure each train/test case is a full set of recommendations for a user\n",
    "def get_test_orders(order_ids, testsize=0.2):\n",
    "    return np.random.choice(order_ids, size = int(math.floor(len(order_ids)*testsize)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "order_ids = np.unique(xgb_labels.order_id.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_order_ids = get_test_orders(order_ids, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = xgb_data[xgb_data.order_id.isin(test_order_ids)]\n",
    "y_test = xgb_labels[xgb_labels.order_id.isin(test_order_ids)]\n",
    "X_train = xgb_data[~xgb_data.order_id.isin(test_order_ids)]\n",
    "y_train = xgb_labels[~xgb_labels.order_id.isin(test_order_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train.drop(['order_id'], axis=1, inplace=True)\n",
    "X_test.drop(['order_id'], axis=1, inplace=True)\n",
    "y_train.drop(['order_id'], axis=1, inplace=True)\n",
    "y_test.drop(['order_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param = {'max_depth':2, 'eta':1, 'silent':1, 'objective':'rank:map' }\n",
    "num_round = 2\n",
    "bst = xgb.train(param, dtrain, num_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = bst.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predsDF = y_test.copy()\n",
    "predsDF['pred_rating'] = preds\n",
    "predsDF = predsDF.join(tester[['order_id', 'recommendation', 'nextInBasket']])\n",
    "predsDF.sort_values(by=['order_id', 'pred_rating'], ascending=False, inplace=True)\n",
    "ranking_positions = range(1,NUM_RECS + 1)\n",
    "predsDF['ranking'] = ranking_positions * len(np.unique(predsDF.order_id.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listed_preds_df = pd.DataFrame(predsDF.groupby('order_id')['recommendation'].apply(list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l2r_recs_dict = {}\n",
    "for orderid in listed_preds_df.index.values:\n",
    "    l2r_recs_dict[orderid] = listed_preds_df.loc[orderid].recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "======================= EVALUATION ======================= <a class=\"anchor\" id=\"eval\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Params:\n",
    "predictions: predictions for ALL orders in the form {order_id:[product_ids ranked]}\n",
    "K: Number of predictions to computer recall score at\n",
    "'''\n",
    "def calculate_recall_K(predictions, K):\n",
    "    success_counter = 0.0\n",
    "    for order in predictions:\n",
    "        truth = lastInBasket.loc[order].values[0]\n",
    "        preds = predictions[order][:K]\n",
    "        for prod in preds:\n",
    "            if prod == truth:\n",
    "                success_counter += 1\n",
    "                \n",
    "    return success_counter/len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Params:\n",
    "predictions: predictions for ALL orders in the form {order_id:[product_ids ranked]}\n",
    "K: Number of predictions to computer mAP score at\n",
    "'''\n",
    "def calculate_map_K(predictions, K):\n",
    "    mAP= 0.0\n",
    "    for order in predictions:\n",
    "        counter = 0.0\n",
    "        truth = lastInBasket.loc[order].values[0]\n",
    "        preds = predictions[order][:K]\n",
    "        for prod in range(len(preds)):\n",
    "            if preds[prod] == truth:\n",
    "                counter += 1\n",
    "                mAP += (counter/(prod+1))\n",
    "    return mAP/len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Need to use Python3 for pytrec_eval, so we pickle recommendations\n",
    "'''\n",
    "def pickle_recs(predictions, modelName, numrecs):\n",
    "    qrel = {}\n",
    "    run = {}\n",
    "    for order in predictions:\n",
    "        pred_scores = {}\n",
    "        true_scores = {}\n",
    "        preds = predictions[order]\n",
    "        for i in range(numrecs):\n",
    "            pred_scores[str(preds[i])] = 1.0/(i+1)\n",
    "            true_scores[str(preds[i])] = 1 if preds[i] == lastInBasket.loc[order].values[0] else 0\n",
    "        run[str(order)] = pred_scores\n",
    "        qrel[str(order)] = true_scores\n",
    "    with open('%s_run.pickle' % modelName, 'wb') as handle:\n",
    "        pickle.dump(run, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open('%s_qrel.pickle' % modelName, 'wb') as handle:\n",
    "        pickle.dump(qrel, handle, protocol=pickle.HIGHEST_PROTOCOL)    \n",
    "    return qrel, run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1291994505835276"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_map_K(implicit_recs, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_recall_K(scipy_recs, 20000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
